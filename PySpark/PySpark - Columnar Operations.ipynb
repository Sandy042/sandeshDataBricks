{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af0f0b3d-bf3e-4a91-a4e1-31067d71da62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df=spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load('/Volumes/sandeshmsdatabricks/sourcefiles/sourcevolume/weather/Brazil_weather_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d5f812c-9ba5-470d-a8ff-673aae039713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Columnar Operation\n",
    "Essential for data transformations,feature engineering and cleaning\n",
    "\n",
    "**WithColumn()** adds/modifies column using expressions\n",
    "- _Syntax: df.withColumn(\"newColumnname\",col(\"col1\")+10)_\n",
    "- _Syntax: df.withColumn(\"newcolumnname\",when(condition,value).otherwise(value))_\n",
    "\n",
    "**drop()** removes column (it returns new df , so we cant perform in place drop)\n",
    "- _Syntax: df=df.drop(\"column_name\")_\n",
    "\n",
    "**alias()** used to rename column\n",
    "- _Syntax: df.select(col(\"colname\").alias(\"newcolname\"))_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7f8d89b-7a81-4792-bc64-c4358fe5f1a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Question 1\n",
    "Add column is_hot_day (1 if Temp_Mean > 25, else 0). Show Country, Date, Temp_Mean, is_hot_day for first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b20ee8f7-e28d-4709-8c12-889df863159d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+----------+\n|Country|      Date|Temp_Mean|is_hot_day|\n+-------+----------+---------+----------+\n| Brazil|2000-01-01|     23.7|         0|\n| Brazil|2000-01-02|     23.5|         0|\n| Brazil|2000-01-03|     23.3|         0|\n| Brazil|2000-01-04|     22.3|         0|\n| Brazil|2000-01-05|     23.7|         0|\n+-------+----------+---------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df=df.withColumn(\"is_hot_day\",when(col(\"Temp_Mean\") >25,1).otherwise(0))\n",
    "\n",
    "df.select(\"Country\",\"Date\",\"Temp_Mean\",\"is_hot_day\")\\\n",
    "    .limit(5)\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6224c484-1a56-4c92-81b5-60dc81e0a460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Question 2\n",
    "Add wind_category: \"High\" if Windgusts_Max > 20, \"Medium\" if >10, else \"Low\". Drop original Windgusts_Max. Show Country, Date, wind_category for 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb46a3d-8d09-41e6-9546-d24c5b4e9be8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+\n|Country|      Date|wind_category|\n+-------+----------+-------------+\n| Brazil|2000-01-01|         High|\n| Brazil|2000-01-02|         High|\n| Brazil|2000-01-03|         High|\n| Brazil|2000-01-04|         High|\n| Brazil|2000-01-05|         High|\n+-------+----------+-------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df=df.withColumn(\"wind_category\",when(col(\"Windgusts_Max\")>20,'High').when(col(\"Windgusts_Max\")>10,'Medium').otherwise(\"Low\"))\\\n",
    ".drop(\"Windgusts_Max\")\\\n",
    ".select(\"Country\",\"Date\",\"wind_category\")\\\n",
    ".show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark - Columnar Operations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}